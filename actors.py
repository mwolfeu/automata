# all the active things in the world

from dataTypes import pAtomicData, aAtomicData, derivedData, actorTime
from dataTypes import xCoord, yCoord, actBool
from genModels import memory, desires
from module import importCode
from random import choice
import math

class goal (): # a lump that does not go anywhere

  def __init__(self, context, learn):
    self.name="Goal"
    self.icon="G"
    self.initX=9
    self.initY=5
    
  def tok(self):
    pass

# Totally grody
class actMethod():  # wrapper used to match actions w required test args
  def __init__(self, method):
    self.method = method

# Capabilities of bot that affect the "world"
# NOTE: could include diagonal at some point
class automataActions():

  def autogenIsTest(self, action): # Totally grody
    code = """
from actors import automataActions
from actors import actMethod
from dataTypes import actBool

a = automataActions
def wave0is_{0}(m: actMethod):
  return (actBool(m.method.__name__ == a.{0}.__name__))
"""
    name=action.__name__
    m = importCode(code.format(name), "autogenerated_action_test")
    fName = 'wave0is_' + name
    return (getattr(m, fName)) # get the staticmethod within the module
    # setattr(self, fName, getattr(m, fName)) #staticmethod()

  def actXPlus (self, c, a):
    c.setWorldLoc (a, c.getWorldInfo(a)["x"] + 1, c.getWorldInfo(a)["y"])

  def actXMinus (self, c, a):
    c.setWorldLoc (a, c.getWorldInfo(a)["x"] - 1, c.getWorldInfo(a)["y"])

  def actYPlus (self, c, a):
    c.setWorldLoc (a, c.getWorldInfo(a)["x"], c.getWorldInfo(a)["y"] + 1)

  def actYMinus (self, c, a):
    c.setWorldLoc (a, c.getWorldInfo(a)["x"], c.getWorldInfo(a)["y"] - 1)
    
  # list of all action method pointers
  def getList(self):
    ops = []
    for i in dir(self):
      if i.startswith('act'):
        ops.append(getattr(self, i))

    return ops

class automata ():
	  
  def __init__(self, context, learn):
    self.name="Bot"
    self.icon="B"
    self.initX=0
    self.initY=0
    self.context = context
    self.learn = learn
    self.memory = memory()
    self.desires = desires()
    self.actions = automataActions()
    self.actionList = self.actions.getList()
    for a in self.actionList:
      self.memory.registerSymbol("aadTests", self.actions.autogenIsTest(a), a)
    
    # the concept below == bot currently on the goal
    botxAD = pAtomicData(0, "padBotX", 0) # value does not matter
    botyAD = pAtomicData(0, "padBotY", 0)
    goalxAD = pAtomicData(0, "padGoalX", 0)
    goalyAD = pAtomicData(0, "padGoalY", 0)
    xeqDD = derivedData(0,0, "xEq", (botxAD,goalxAD), True)
    yeqDD = derivedData(0,0, "yEq", (botyAD,goalyAD), True)
    desire0=derivedData(0,0, "AND", (xeqDD,yeqDD), True)
    
    self.desires.registerWant("goalTouch", desire0)  # inject the first desire
    
    acTime = pAtomicData(0, "actorTime", 0) # value does not matter
    minRun = pAtomicData(0, "minRun", 0)
    desire1=derivedData(0,0, "timeEq", (acTime,minRun), True)
    
    self.desires.registerWant("overtime", desire1)  # will trigger step before minRun exceeded
    
    self.aadAction = None


  # This can get a loooot more complicated in the future. Like: I saw something before (I have data)... now it is occluded (no data)
  def setPassiveAD(self): # commit pAD to timestate model
    for actor in self.context.getAllActorsLocations(self): # see everyone you can
      self.memory.tsAdd(pAtomicData(self.memory.time, "pad" + actor["name"] + "X", xCoord(actor["x"])))
      self.memory.tsAdd(pAtomicData(self.memory.time, "pad" + actor["name"] + "Y", yCoord(actor["y"])))
      
      self.memory.tsAdd(pAtomicData(self.memory.time, "actorTime", actorTime(self.memory.time)))
      if len(self.learn.store): # if you already have a min run
        self.memory.tsAdd(pAtomicData(self.memory.time, "minRun", actorTime(self.learn.store["goalTouch"]["minRun"]))) # shouldn't be hardcoded to "goalTouch"

    self.memory.deriver("padTests")
      
  def setActiveAD(self):
    self.memory.tsAdd(aAtomicData(self.memory.time, self.aadAction.method.__name__, self.aadAction))
    self.memory.deriver("aadTests")

  def act (self):
    suggestions = self.learn.getSuggestions(self.memory.testAgainstCurrent)
    if len(suggestions) > 0:
      import code						# drop to interpreter
      code.interact(local=locals())
      action = suggestions[0][0]   # hardcoded to choose best action in list.  nuance?
    else:
      action = choice(self.actionList)

    self.aadAction = actMethod(action) # wrap in actMethod object for aad
    action(self.context, self) # aaaaand what if world sez piss off to action.  need to relay this back up the stack so we don't choose it again.
    
  def setDD(self):
    self.memory.deriver("relationTests")   # run AND tests

  # print important per-step context data
  def printContext(self):
    print ("\rTime:", self.memory.getTime(), " "*30, end="")
    
  def getDist (self, run): #FIXME need to be derived.  shoudn't be hardcoded forever.
    x1 = self.memory.findValue ("padBotX", run[-1])
    y1 = self.memory.findValue ("padBotY", run[-1])
    x2 = self.memory.findValue ("padGoalX", run[-1])
    y2 = self.memory.findValue ("padGoalY", run[-1])
    
    return ( math.sqrt((x2 - x1)**2 + (y2 - y1)**2) )
    
  def testWants (self):
    for want in self.desires.testWants(self.memory.testAgainstCurrent):  # passing a fcn is stupid TODO
      print("\rDesire fulfilled !!!!", want, end="")
      self.learn.registerRun("goalTouch", self.memory.timeState, self.getDist) # "goalTouch" was 'want'  should be some combo of actor too
      return (True)
    return(False)
    
  def finish(self):
    if self.testWants():
      return (True)
    self.memory.advanceTime()
    return(False)
    
  def tok(self): # one tick of the clock... make the most of it...
    self.setPassiveAD()  # record all passive data & run tests
          
    self.act() # choose an action, record it, do it
        
    self.setActiveAD()   # record all active data & run tests
      
    self.printContext()
      
    self.setDD()
    return( self.finish() )
